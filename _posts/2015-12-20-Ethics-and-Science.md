---
layout:	post
title:	On the Ethics of Doing Science in the First Place
tags:	[physics, science, philosophy, pragmatism]
---


In every post I've written, I wrestle with the urge begin with a disclaimer about how I really have no idea about anything. This time my resolve was weak.

I really have no idea about anything.

### Ethics

Recently at ISC (I'll have to write a post about ISC at some point), Alex Breitweser brought up the distinction between Kantian and utilitarian ethics. According to my embarrassingly superficial understanding, Kant, a "deontologist", held that the morality of a deed can only be judged on the basis of the doer's *intentions*. Contrast this with the theories of Bentham and Mill, who believed that the rightness or wrongness of an act is determined solely by its tangible *effects* ("consequentialism") -- and moreover, on the benefits or costs those might bring to society at large ("utilitarianism").

#### Utilitarians

Bentham, for instance, is well known for his maxim "strive toward the greatest good for the greatest number". In principle, this seems both reasonable and laudable; but matters rapidly become turbid when one has to decide what exactly qualifies as "good", and how much weight to assign to competing goods (not to mention competing bads). In the context of the plurality of human circumstances, cultures and dispositions, it would seem that any quest for an objective / universal good is hopeless.

Therefore, a morality-judgement made within the utilitarian framework might be worse than useless without an explicit and honest statement of a "utility goal": that is, what you (the judge) think we ought to strive for: what "good" you want to maximise. Unfortunately, any given utility goal will be at least partially incompatible with other legitimate utility goals. E.g. I want to lower the tax burden on citizens, but you want to ensure that everyone has access to healthcare. They are subjective and open to debate; we must always ask "Who is judging? And on what criteria?".

Even if we put this subjectivity to one side for the moment, I think you'll agree that a theory of morality is pretty feeble if it only allows us to judge *past* outcomes. So the foregoing has to be extended to provide guidance on how to *act* to achieve our utility goals. In order to act effectively we must propose a "utility function" which maps between actions in the real world and outcomes favourable (or otherwise) to the utility goal. Here lies another potential source of disagreement, as two people might have the very same utility goals, but propose vastly different utility functions. E.g. both want everyone to have free healthcare, but one thinks the best way to do this is through government-run hospitals and the other thinks the government should just foot the bill when someone visits a private hospital.

For any utility goal (or set thereof), there is an infinite number of utility functions. And some of these functions will be better than others, in that the actions they prescribe will more effectively realise the goal. Clearly someone who focusses solely on consequences in isolation, and pays no heed to how those consequences came about (i.e. someone who focusses on the ends and not the diversity of means) will rob themselves of an opportunity to better maximise their utility in the future.

Yet utilitarianism is silent on this crucial issue, providing no framework for the construction or optimisation of utility functions. In this light, we must conclude that basic utilitarian morality is immoral according to utilitarian morality (but moral according to Kant, who I'll get to now).


#### Deontologists

Kant is more restrictive about the meaning of "a moral good": roughly, he held that a person's *noble intention* is the only unassailable good, and that any other apparent good, like courage or happiness, must be accompanied by some qualifications. For instance, a person of political consequence might publicly support the establishment of free healthcare only because they've shorted stocks in private health insurers -- although many would agree that the objective is noble, the intentions are not and so Kant would classify this as immoral. I think it was examples such as this (though probably not this exact one) that led Kant to dismiss the focus on outcomes: base self-interest can masquerade as a noble utility goal; and conversely, the best-laid schemes o' mice an' men gang aft tits-up when unpredictable circumstances turn a well-meaning act into a disaster, and to blame a victim of circumstance seems perverse.

At the heart of this reasoning is Kant's belief in free will. It is sensible to demand that morality should be based on things that human agents can control. Intentions are under our control; outcomes are not.

Taking this further, actions taken on the basis of feelings / emotions are in some sense immoral, again because the only moral acts are those that emerge from our free will and conscious decision to do *the right thing*. To answer the obvious next question, "What is *the right thing*?", Kant constructed his theory of the Categorical Imperative. I won't go into this, because I have in mind that this post should end at some point and honestly I'm unqualified to write about any of this stuff; but one of Kant's conclusions from this was that humans have a right to not be treated as "a means to an end". We should therefore be suspicious of utilitarianism, which will always demand that we sacrifice our rights for the greater good.

Now, an obvious consequence of Kant's ethics is the impossibility of objectively judging other people's actions. Anyone accused of a misdeed can *claim* that they meant well: no-one except some omniscient afterlife judge could prove otherwise. And so for the immediate purposes of our corporeal existence, the person in question must be declared innocent regardless of the truth of the matter.

More importantly for me however, is that even if they *did* mean well, the disconnection between intentions, actions, and consequences renders learning from mistakes optional or irrelevant. It brings the person who puts a good deal of thought into their actions on the same moral footing as someone who doesn't, as long as their intentions are the same.


#### Negligence and Pragmatism

So, both the approaches I have outlined are powerless to adequately resolve ethical questions (though for different reasons). Utilitarianism suffers on the one hand from subjectivity in judging the utility goal, and on the other from overwhelming choice in the utility function -- choice which the theory is ill-equipped to restrict without broad evidence-based historical analysis. So, though utilitarianism is a nice punchy principle, in an unpredictable world containing more than one person, the morality it prescribes seems most unsatisfactory. Kant, for his part, gives us a theory whose conceptual roots (which I didn't address) are deeply founded upon reason -- so deep that he seems to reject empiricism altogether, while failing to observe that humans are not rational. A theory so dislocated from the world has no business teaching us how to live in it.

These theoretical oversights are ripe for exploitation, failing as they do to penalise negligence when formulating our intentions, our goals and our actions. For instance, a government which is dedicated to public healthcare might, inadvertently or advertently, make it impossible for competing private healthcare to be economically viable, leading to a state monopoly. Ten years down the line, a new government finds it necessary for whatever reason to cut the national budget, and people find themselves coping with a dysfunctional underfunded public service, with no alternative. Had the first government done more research, it would have found that state monopolies not only frequently underperform compared to services in a competitive environment, but furthermore that they are very risky because states and national finances can fail unexpectedly. That was a long-winded and indirect way of saying that *we must accept the world as it is and not our self-serving / expedient idealisations of it*. We must incorporate *pragmatism* into morality.


### Science

Finally the good stuff. How does science come into this discussion?

Well, the question of how much responsibility scientists should take for the outcomes of their research is one that goes back well before Frankenstein. In this context, it is not uncommon to hear the sentiment that pure knowledge has *no inherent morality* -- in different hands it can be used for good or for evil. In the Kantian interpretation, this amorality would seem to excuse scientists from any censure (as long as their methods respect the tenets of the Categorical Imperative and do not infringe upon human rights).

However, from a utilitarian standpoint, the claim of neutrality backfires to immorality: a lot of time, money and other resources are spent on activities which are, allegedly, not intrinsically beneficial to humanity.

A credible argument for science must therefore prove that it is *good* rather than merely *not bad*. Of course there are many examples to this effect -- long-distance communications, advances in medicine, agricultural technologies which have vastly increased our capacity to feed (some) people, etc. Yet of course these incredible achievements are always accompanied by a slew of negative contributions: mass extinction, climate change, biological and nuclear weapons, etc. We need no reminding that we're not the greatest custodians of our own survival: science has authored terrors of existential proportions, as well as wonders and salvations.

With this in mind, if we return to my "Kantian" picture of morality, things don't look so promising for the scientists -- it is now clear that for them to believe their trade morally neutral is a (wilful?) negligence: a self-serving self-deception based on a hollow and counterfactual faith in humanity.
The pessimist might say that, like Doctor Frankenstein, we're in a constant race against our creations, perpetually battling to contain our  thoughtlessly thoughtful meddling. The fact that we've survived this far guarantees precisely zero about our future prospects.

Anyway, I've ventured onto well-trodden territory and should move on. I suppose the broad conclusion, which was obvious well before you started reading this, is that the moral case for science as a whole has some pretty dicey areas.


#### But this is what I really came here to say

Let me take a step back from the familiar cataclysms of the last section and indulge in constructing a new one.

First, some broad claims. It goes without saying that science has brought humankind incredible insight into the natural world, allowing us to understand, predict and manipulate it. Thus, the human race has acquired substantial power.

It also goes without saying that humans are given to cruelty and exploitiveness, both direct and indirect, inflicted on the weak by the powerful. Not all humans are affected to the same extent, but, perversely, those who *are* are more likely to covet and ascend to positions of power. (This is a law derived from logic, akin to Natural Selection; it is why there can never be a benevolent dictatorship.) Moreover, there seems to be ample evidence of the addictive properties of power, leading to a positive-feedback loop of imbalances and aggression against the disenfranchised.

From one perspective, therefore, the quest for new knowledge (and its concomitant power) is inadvertently a quest for ever-more sophisticated implements of exploitation and oppression. This leads inexorably to the suggestion that *until we reach a level of maturity where we are able to work toward a coherent global vision for our species, the pursuit of science is morally wrong*.

It's a crude argument, I grant you. But still, perhaps the greatest gift we could give to future generations would be to stop discovering new things until we're sure we've come to terms with the old.